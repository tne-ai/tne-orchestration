import asyncio
import random
from typing import Callable

from v2.api.api import LlmOutput, RagRecord
from v2.app.state import State


def simulate_unit_score() -> float:
    return random.uniform(0.0, 1.0)


async def simulate_latency(min_secs: float, max_secs: float) -> None:
    assert 0 <= min_secs <= max_secs
    sleep_secs = random.uniform(min_secs, max_secs)
    await asyncio.sleep(sleep_secs)


async def simulate_generating_segments(
    state: State, todo_fun_name: str, record_creator: Callable[[LlmOutput], RagRecord]
) -> None:
    full_str = (
        f"TODO(Guy): Implement {todo_fun_name}. "
        f"This is just some placeholder text for {todo_fun_name}. "
        f"It should be properly generated by {todo_fun_name}. "
        f"This is the end of simulated text for {todo_fun_name}."
    )
    segment_count = 30
    if len(full_str) < segment_count:
        segments = list(full_str)
    else:
        indexes = [i * len(full_str) // segment_count for i in range(segment_count)]
        indexes.append(len(full_str))
        segments = [full_str[indexes[i] : indexes[i + 1]] for i in range(segment_count)]
    for index, segment in enumerate(segments):
        await simulate_latency(0.02, 0.2)  # Average 110 ms.
        if index < len(segments) - 1:
            llm_output = LlmOutput(text=segment)
        else:
            llm_output = LlmOutput(text=segment, is_complete=True, token_count=1234)
        await state.put_record_obj(record_creator(llm_output))
